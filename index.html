<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.6.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.6.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.6.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="某航空人">
<meta property="og:type" content="website">
<meta property="og:title" content="Tangmeii_Sites">
<meta property="og:url" content="http://tangmeii.cn/index.html">
<meta property="og:site_name" content="Tangmeii_Sites">
<meta property="og:description" content="某航空人">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tangmeii_Sites">
<meta name="twitter:description" content="某航空人">






  <link rel="canonical" href="http://tangmeii.cn/">



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Tangmeii_Sites</title>
  











  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">


  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tangmeii_Sites</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类<span class="badge">3</span></a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-schedule">

    
    
    
      
    

    
      
    

    <a href="/schedule/" rel="section"><i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>日程表</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tangmeii.cn/2020/07/01/Kalman-Filter/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gengxiang">
      <meta itemprop="description" content="某航空人">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tangmeii_Sites">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/07/01/Kalman-Filter/" class="post-title-link" itemprop="http://tangmeii.cn/index.html">Kalman Filter</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-07-01 11:10:23 / 修改时间：11:26:56" itemprop="dateCreated datePublished" datetime="2020-07-01T11:10:23+08:00">2020-07-01</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/学习/" itemprop="url" rel="index"><span itemprop="name">学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="1-离散卡尔曼滤波"><a href="#1-离散卡尔曼滤波" class="headerlink" title="1.  离散卡尔曼滤波"></a>1.  离散卡尔曼滤波</h2><h4 id="待估计的过程"><a href="#待估计的过程" class="headerlink" title="待估计的过程"></a>待估计的过程</h4><p>卡尔曼滤波解决的是离散控制过程状态估计问题，状态$x \in \Re^{n}$， 系统由线性随机差分方程控制：</p>
<script type="math/tex; mode=display">
x_k = Ax_{k-1} + Bu_{k-1} + w_{k-1}</script>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2020/07/01/Kalman-Filter/" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
         
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tangmeii.cn/2020/04/18/近似推断/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gengxiang">
      <meta itemprop="description" content="某航空人">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tangmeii_Sites">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/04/18/近似推断/" class="post-title-link" itemprop="http://tangmeii.cn/index.html">Hexo 重要操作</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-04-18 14:13:07" itemprop="dateCreated datePublished" datetime="2020-04-18T14:13:07+08:00">2020-04-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2020-02-12 18:45:00" itemprop="dateModified" datetime="2020-02-12T18:45:00+08:00">2020-02-12</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/学习/" itemprop="url" rel="index"><span itemprop="name">学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>&emsp;&emsp;博客基于<a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">Hexo</a>，主题基于<a href="http://theme-next.iissnan.com/getting-started.html" target="_blank" rel="noopener">Next</a>，这里记录一些重要操作。<br></p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2020/04/18/近似推断/" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
         
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tangmeii.cn/2020/01/11/Distribution-Embedding/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gengxiang">
      <meta itemprop="description" content="某航空人">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tangmeii_Sites">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/01/11/Distribution-Embedding/" class="post-title-link" itemprop="http://tangmeii.cn/index.html">Distribution Embedding</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-01-11 21:04:32" itemprop="dateCreated datePublished" datetime="2020-01-11T21:04:32+08:00">2020-01-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2020-01-13 14:48:53" itemprop="dateModified" datetime="2020-01-13T14:48:53+08:00">2020-01-13</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>衡量分布距离在机器学习算法中非常常用，然而分布估计往往运算量大，又不够准确。将分布映射到RKHS上，可以带来很好的性质，因此本篇介绍一下分布嵌入算子，包括边缘嵌入算子，条件嵌入算子和联合嵌入算子。</p>
<h3 id="条件嵌入算子"><a href="#条件嵌入算子" class="headerlink" title="条件嵌入算子"></a>条件嵌入算子</h3><p>交叉协方差算子，Cross-covariance operators，注意，元素相乘，并不是内积。</p>
<script type="math/tex; mode=display">
\mathcal{C}_{Y X}:=\mathbb{E}_{Y X}[\varphi(Y) \otimes \phi(X)]=\mu_{\mathbb{P}_{Y X}}</script><p>边缘嵌入算子定义</p>
<script type="math/tex; mode=display">
\mu_{\mathbb{P}}=\mathbb{E}_{\mathbf{x} \sim \mathbb{P}}[\varphi(\mathbf{x}-\cdot)]=\varphi * \mathbb{P}</script><p>边缘嵌入算子的估计值：可以理解为半个映射</p>
<script type="math/tex; mode=display">
\hat{\mu}_{\mathbb{P}}:=\frac{1}{n} \sum_{i=1}^{n} k\left(\mathbf{x}_{i}, \cdot\right)</script><p>条件嵌入算子 $\mathcal{U}_{Y | X}: \mathscr{H} \rightarrow \mathscr{G}$ 为算子，是分布$P(Y | X)$的均值嵌入，即函数到函数的映射</p>
<script type="math/tex; mode=display">
\mathcal{U}_{Y | X}:=\mathcal{C}_{Y X} \mathcal{C}_{X X}^{-1}</script><p>而条件嵌入值 $\mathcal{U}_{Y | \mathbf{x}_<em>} \in \mathscr{G}$ 为预测值，是分布$P(Y | X=\mathbf{x}_</em>)$的嵌入:</p>
<script type="math/tex; mode=display">
\mathcal{U}_{Y | \mathbf{x}_*}:=\mathcal{C}_{Y X} \mathcal{C}_{X X}^{-1} k(\mathbf{x}_*, \cdot)</script><h3 id="条件嵌入算子估计"><a href="#条件嵌入算子估计" class="headerlink" title="条件嵌入算子估计"></a>条件嵌入算子估计</h3><p>当我们有观测值$\mathbf{X},\mathbf{Y}$的时侯，条件嵌入算子就可以估计了。设映射$\phi:\mathcal{X} \rightarrow \mathscr{H} \text { and } \varphi: \mathcal{Y} \rightarrow \mathscr{G}$, 且$\Phi:=\left[\varphi\left(\mathbf{y}_{1}\right), \ldots, \varphi\left(\mathbf{y}_{n}\right)\right]^{\top} \text { 且} \Upsilon:=\left[\phi\left(\mathbf{x}_{1}\right), \ldots, \phi\left(\mathbf{x}_{n}\right)\right]^{\top}$ ，则有：</p>
<p>条件均值嵌入估计，即给定$\mathbf{X,Y}$预测$\mathbf{x_*}$：</p>
<script type="math/tex; mode=display">
\begin{array}
\hat{\mu}_{Y | \mathbf{x}_*}&=\widehat{\mathcal{C}}_{Y X}\left(\widehat{\mathcal{C}}_{X X}+\lambda \mathcal{I}\right)^{-1} k(\mathbf{x}_*, \cdot) \\
&=\frac{1}{n} \Phi \Upsilon^{\top}\left(\frac{1}{n} \Upsilon \Upsilon^{\top}+\lambda \mathcal{I}\right)^{-1} k(\mathbf{x}_*, \cdot) \\
&=\Phi \Upsilon^{\top}\left(\Upsilon \Upsilon^{\top}+n \lambda \mathcal{I}\right)^{-1} k(\mathbf{x}_*, \cdot) \\
&=\Phi\left(\Upsilon^{\top} \Upsilon+n \lambda \mathbf{I}_{n}\right)^{-1} \Upsilon^{\top} k(\mathbf{x}_*, \cdot) \\
&=\Phi\left(\mathbf{K}+n \lambda \mathbf{I}_{n}\right)^{-1} \mathbf{k}_{\mathbf{Xx}_*}
\end{array}</script><p>请注意，<strong>条件均值嵌入</strong>非常像最小二乘解析解，其实一个道理，具体如下：</p>
<script type="math/tex; mode=display">
\begin{array}
1\mathbf{w}\mathbf{X} =\mathbf{Y}\\
\mathbf{w}\mathbf{X}\mathbf{X}^{\top}=\mathbf{Y}\mathbf{X}^{\top}\\
\mathbf{w}=\mathbf{Y}\mathbf{X}^{\top}(\mathbf{X}\mathbf{X}^{\top}+\lambda\mathbf{I})^{-1}\\
\mathbf{w}=\mathbf{K}_\mathbf{YX}(\mathbf{K}_\mathbf{XX}+\lambda\mathbf{I})^{-1}\\
有条件： \mathbf{X}^{\top}(\mathbf{X}\mathbf{X}^{\top}+\lambda\mathbf{I})=\mathbf{X}^{\top}(\mathbf{X}\mathbf{X}^{\top}+\lambda\mathbf{I})\\
 先右乘： (\mathbf{X}\mathbf{X}^{\top}+\lambda\mathbf{I})^{-1}再左乘 \mathbf{Y}(\mathbf{X}\mathbf{X}^{\top}+\lambda\mathbf{I})^{-1}\\
 即得到：\mathbf{w}=\mathbf{Y}(\mathbf{X}^{\top}\mathbf{X}+\lambda\mathbf{I})^{-1}\mathbf{X}^{\top}\\
 核表示：\mathbf{w}=\Phi(\mathbf{K}_{\mathbf{x}\mathbf{x}}+\lambda\mathbf{I})^{-1}\Upsilon\\

\end{array}</script><h3 id="核运算规则"><a href="#核运算规则" class="headerlink" title="核运算规则"></a>核运算规则</h3><p>条件算子到边缘算子的关系为：</p>
<script type="math/tex; mode=display">
\mu_{X}=\mathbb{E}_{Y}\left[\mathcal{U}_{X | Y} \varphi(Y)\right]=\mathcal{U}_{X | Y} \mathbb{E}_{Y}[\varphi(Y)]=\mathcal{U}_{X | Y} \mu_{Y}</script><p>边缘算子的估计值为【注意这里$XY$和上问有调换，其实都一样】：</p>
<script type="math/tex; mode=display">
\hat{\mu}_{X}=\hat{\mathcal{U}}_{X | Y} \hat{\mu}_{Y}=\widehat{\mathcal{C}}_{X Y} \hat{\mathcal{C}}_{Y Y}^{-1} \hat{\mu}_{Y}=\Upsilon(\mathbf{L}+n \lambda \mathbf{I})^{-1} \tilde{\mathbf{L}} \alpha</script><p>请注意，这里的意思是 $\hat{\mathcal{U}}_{X | Y}$已知的情况下，如何根据给定的 $\hat{\mu}_{Y}$ 得到对应的 $\hat{\mu}_{X}$。换成上面的核岭回归就容易理解了， $\hat{\mathcal{U}}_{X | Y}$ 相当于求解出的系数$\mathbf{w}$，有了系数之后，给输入$Y$，即可得到输出$X$。</p>
<p>联合分布嵌入算子表示为：</p>
<script type="math/tex; mode=display">
\mu_{X Y}=\mathcal{U}_{X | Y} \mu_{Y}^{\otimes}=\mathcal{U}_{Y | X} \mu_{X}^{\otimes}</script><p>其中$\mu_{X}^{\otimes}:=\mathbb{E}_{X}[\phi(X) \otimes \phi(X)]$ and $\mu_{Y}^{\otimes}:=\mathbb{E}_{Y}[\varphi(Y) \otimes \varphi(Y)]$ , 用方差算子的方式表示为：</p>
<script type="math/tex; mode=display">
\mathcal{C}_{X Y}=\mathcal{U}_{X | Y} \mathcal{C}_{Y Y} \quad and \quad \mathcal{C}_{Y X}=\mathcal{U}_{Y | X} \mathcal{C}_{X X}</script><h3 id="条件独立判据"><a href="#条件独立判据" class="headerlink" title="条件独立判据"></a>条件独立判据</h3><p>假设联合分布满足：$P(X,Y,Z)=P(X|Z)P(Y|Z)P(Z)$，即$X,Y$是条件$Z$下的两个独立变量：</p>
<p>2008年提出标准化条件交叉方差算子：</p>
<script type="math/tex; mode=display">
\mathcal{V}_{Y X | Z}:=\mathcal{V}_{Y X}-\mathcal{V}_{Y Z} \mathcal{V}_{Z X}</script><p>其中 $\mathcal{C}_{Y X}=\mathcal{C}_{Y Y}^{1 / 2} \mathcal{V}_{Y X} \mathcal{C}_{X X}^{1 / 2}$ ，类似于协方差矩阵标准化一样，基于此定义，可以得到偏差判据：</p>
<script type="math/tex; mode=display">
I_{condition}(X, Y | Z)=\left\|V_{\ddot{Y} \dot{X} | Z}\right\|_{H S}^{2}</script><p>那么这个判据可以盘算$X,Y$是否条件独立。 </p>
<h3 id="条件嵌入分布差异判据"><a href="#条件嵌入分布差异判据" class="headerlink" title="条件嵌入分布差异判据"></a>条件嵌入分布差异判据</h3><p>目前有Zhang和Wang两种，经过分析，还是决定用Wang的HS判据</p>

          
        
      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tangmeii.cn/2020/01/09/GMMTL_2020/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gengxiang">
      <meta itemprop="description" content="某航空人">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tangmeii_Sites">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/01/09/GMMTL_2020/" class="post-title-link" itemprop="http://tangmeii.cn/index.html">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-01-09 09:48:37" itemprop="dateCreated datePublished" datetime="2020-01-09T09:48:37+08:00">2020-01-09</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2020-06-02 21:43:47" itemprop="dateModified" datetime="2020-06-02T21:43:47+08:00">2020-06-02</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<hr>
<h1 id="2020年01月09日-方案示例"><a href="#2020年01月09日-方案示例" class="headerlink" title="2020年01月09日 方案示例"></a><strong>2020年01月09日</strong> 方案示例</h1><p>[TOC]</p>
<h3 id="0-七个问题"><a href="#0-七个问题" class="headerlink" title="0.七个问题"></a>0.七个问题</h3><p><strong>背景</strong>：数据驱动方法广泛应用于各个领域，而且需要标签数据。制造领域许多问题的标签数据获取成本非常高，因此一个重要的思路的就是迁移学习，而制造领域中常见的一类问题是条件分布偏差的回归问题，几乎没有得到关注。</p>
<p><strong>问题：</strong>如何解决条件分布差异的回归迁移问题</p>
<p><strong>现状</strong>：如下</p>
<ul>
<li>将目标求解问题<strong>转化</strong>为求<strong>权重</strong>问题，基于目标数据求源数据的权重</li>
<li>将目标求解问题<strong>转化</strong>为求<strong>映射</strong>问题，基于目标数据求映射</li>
<li>将目标求解问题<strong>转化</strong>为求<strong>残差</strong>问题，基于目标数据求残差函数</li>
</ul>
<p><strong>GAP</strong>:  现有方法难以保证精度和稳定性，仍依赖大量目标数据</p>
<p><strong>难点</strong>：现有的转化方式并没有改变‘<strong>目标不充分</strong>’问题的本质，仍是<strong>非适定问题</strong>。</p>
<p><strong>创新点</strong>：利用边缘分布相等条件，将目标模型求解问题转化为解空间更小的低维问题。引入隐变量，使得难以求解的函数转化为有限个隐变量参数。</p>
<p><strong>方案</strong>：</p>
<ul>
<li>迁移问题转换</li>
<li>变量求解</li>
<li>求边界泛化</li>
</ul>
<p><strong>验证</strong>：</p>
<ul>
<li><p>刀尖模态参数预测问题</p>
</li>
<li><p>末端负载预测问题</p>
</li>
<li><p>再找其他数据集</p>
</li>
</ul>
<h3 id="1-问题定义"><a href="#1-问题定义" class="headerlink" title="1.问题定义"></a>1.问题定义</h3><p>假设已有源回归任务包含大量训练数据 $\mathcal{D}_S=\left\{\left(\mathbf{x}_1^s,y_1^s\right),\ldots,\left(\mathbf{x}_{n_s}^s,y_{n_s}^s\right)\right\}$ , 其中 $\mathbf{x}_i^s\in\mathcal{X}_S$ 是源数据特征， $y_i^s\in\mathcal{Y}_S$ 是源数据标签，回归任务因此标签为连续变量。同时有另一个相似的回归任务，仅有少量的标签数据 $\mathcal{D}_T=\left\{\left(\mathbf{x}_1^t,y_1^t\right),\ldots,\left(\mathbf{x}_{n_t}^t,y_{n_t}^t\right)\right\}$ , 其中 $\mathbf{x}_i^t  \in \mathcal{X}_T$ 是输入， $y_i^t\in\mathcal{Y}_T$ 对应的输出。此处所关注的是两个回归任务的条件偏移场景，即假设边缘分布相同 ​，而条件分布不同，即$p\left(y_s\middle|\mathbf{x}_s\right)\neq p\left(y_t\middle|\mathbf{x}_t\right)$。</p>
<p>为了后面更加清晰描述，此处定义清楚两数据集的所需表示：</p>
<p>源数据    $\mathcal{D}_s$, 包含输入特征矩阵 ${\mathbf{X}}_s\in\mathbb{R}^{n_s\times d}$ 和输出标签向量 ${\mathbf{y}}_s\in\mathbb{R}^{n_s\times 1}$ :</p>
<script type="math/tex; mode=display">
\mathbf{X}_{s}=\left[\mathbf{x}_{1}^{s}, \mathbf{x}_{2}^{s}, \ldots, \mathbf{x}_{n_{s}}^{s}\right]^{\top}, \mathbf{y}_{s}=\left[y_{1}^{s}, y_{2}^{s}, \ldots, y_{n_{s}}^{s}\right]^{\top}</script><p>目标数据 $\mathcal{D}_t$, 包含输入特征矩阵 ${\mathbf{X}}_t\in\mathbb{R}^{n_t\times d}$ 和输出标签向量 ${\mathbf{y}}_t\in\mathbb{R}^{n_t\times 1}$ :</p>
<script type="math/tex; mode=display">
\mathbf{X}_{t}=\left[\mathbf{x}_{1}^{t}, \mathbf{x}_{2}^{t}, \ldots, \mathbf{x}_{n_{t}}^{t}\right]^{\top}, \mathbf{y}_{t}=\left[y_{1}^{t}, y_{2}^{t}, \ldots, y_{n_{t}}^{t}\right]^{\top}</script><h3 id="2-问题转化"><a href="#2-问题转化" class="headerlink" title="2. 问题转化"></a>2. 问题转化</h3><p><img src="/2020/01/09/GMMTL_2020/Fig1 Illustration of conditional distribution shift.svg" style="zoom:60%;"></p>
<h4 id="2-1-引出偏差分布"><a href="#2-1-引出偏差分布" class="headerlink" title="2.1 引出偏差分布"></a>2.1 引出偏差分布</h4><p>首先假设源模型和目标模型分别为$f_s(\mathbf{x})$ 和 $f_t(\mathbf{x})$，观测标签值表示为：</p>
<script type="math/tex; mode=display">
y_s=f_s(\mathbf{x})+\epsilon ,\ \ y_t=f_s(\mathbf{x})+\epsilon</script><p>由于源数据数量充分，因此认为$f_s(\mathbf{x})$ 是已知函数， $f_t(\mathbf{x})$是未知函数，待求。</p>
<p>其中噪声服从均值0，方差$\sigma_n^2$ 的高斯分布，即：</p>
<script type="math/tex; mode=display">
\varepsilon \sim \mathcal{N}\left(0, \sigma_{n}^{2}\right)</script><p>因此，条件概率可以表示为：</p>
<script type="math/tex; mode=display">
p(y_s|\mathbf{x})=\mathcal{N}\left(f_s(\mathbf{x}), \sigma_{n}^{2}\right)</script><script type="math/tex; mode=display">
p(y_t|\mathbf{x})=\mathcal{N}\left(f_t(\mathbf{x}), \sigma_{n}^{2}\right)</script><p>带入所有的样本，表示为：</p>
<script type="math/tex; mode=display">
p(\mathbf{y}_s|\mathbf{X}_s)=\mathcal{N}\left(f_s(\mathbf{X}_s), \sigma_{n}^{2}\right)</script><script type="math/tex; mode=display">
p(\mathbf{y}_t|\mathbf{X}_t)=\mathcal{N}\left(f_t(\mathbf{X}_t), \sigma_{n}^{2}\right)</script><p>在整个特征空间范围内，将条件分布差异定义为偏差项(<code>discrepance</code>)定义为 $h(\mathbf{x})$，由于期望取值为连续变量，因此残差项总可以表示为：</p>
<p><strong>这里是示意，概率是不能相减的</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}

p(h|\mathbf{x}) &=\  p(y_t|\mathbf{x})-p(y_s|\mathbf{x})\\
 &= \mathcal{N}\left(f_t(\mathbf{x}), \sigma_{n}^{2}\right)-\mathcal{N}\left(f_s(\mathbf{x}), \sigma_{n}^{2}\right) \\
 &=\mathcal{N}(f_t(\mathbf{x})-f_s(\mathbf{x}),2\sigma_{n}^{2})
\end{aligned}</script><p>因此迁移问题转换成求解偏差条件分布 $p(h|\mathbf{x})$， 由于$f_s(\mathbf{x})$ 和$f_t(\mathbf{x})$ 都是未知的，对于已有的目标数据 $\mathcal{D}_S$和 $\mathcal{D}_T$，数据样本也不一样，因此无法直接求解 $p(h|\mathbf{x})$ ，只能使得源数据加上偏差项之后，条件分布尽可能逼近目标数据，即：</p>
<p>定义加偏置项之后的源数据为$[\mathbf{X}_s,\mathbf{y}_s^{new}]$，则有: </p>
<script type="math/tex; mode=display">
p(\mathbf{y}_s^{new}|\mathbf{X}_s) =  p(\mathbf{h}|\mathbf{X}_s)+p(y_s|\mathbf{X}_s)</script><p>从而满足</p>
<script type="math/tex; mode=display">
\mathbf{h}=\arg \min _{ \mathbf{h}\in \mathbb{R}^{ns}} Dist[(p(\mathbf{y}_s^{new}|\mathbf{X}_s) ,p(\mathbf{y}_t|\mathbf{X}_t) ]</script><p>此处的距离函数可以用核均值距离，也可以用条件期望代替每个分布，从而简化问题。然而，无论如何转化，所求解的未知量$\mathbf{h}\in \mathbb{R}^{ns}$ 的维度是很大的（$ns&lt;&lt;nt$），仅以此约束求解是相当不稳定的。<strong>在此我们要利用边缘分布相同条件，引入隐变量，使得难以求解的问题，转换为一个更加简单的问题</strong>。</p>
<h4 id="2-2-高斯混合模型描述特征空间分布"><a href="#2-2-高斯混合模型描述特征空间分布" class="headerlink" title="2.2 高斯混合模型描述特征空间分布"></a>2.2 高斯混合模型描述特征空间分布</h4><p>考虑到 $p(\mathbf{x}_s)=p(\mathbf{x}_t)$ ，因此我们用一组$K$维混合高斯分布来描述两个领域的特征空间分布：</p>
<script type="math/tex; mode=display">
p(\mathbf{x})=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)</script><p>即$p(\mathbf{x}_s)=p(\mathbf{x}_t)=p(\mathbf{x})$，其中$\sum_{k=1}^{K} \pi_{k}=1$ 为高斯混合模型的混合系数。此时，为了描述变量对与每个高斯高斯分布的归属情况， 我们引入变量 $\mathbf{z}\in\mathbb{R}^{K\times 1}$ ，向量 $\mathbf{z}$ 只有一个元素为1，其他元素都为0，也就是$\sum_{k} z_{k}=1$， 因此向量 $\mathbf{z}$ 共有 $K$ 种状态，对于样本 $\mathbf{x}$ 归属于第 $k$ 个高斯分布的情况，即 $z_k=1$，其概率可以表示为高斯混合模型的混合系数，即$p\left(z_{k}=1\right)=\pi_{k}$。由于向量中只有一个量为1，其他都为0，那么向量 $\mathbf{z}$ 的概率可以表示为 $p(\mathbf{z})=\prod_{k=1}^{K} \pi_{k}^{z_{k}}$。</p>
<p>在隐变量 $\mathbf{z}$ 的存在之下，观测样本$\mathbf{x}$的概率可以表示为：</p>
<script type="math/tex; mode=display">
p(\mathbf{x})=\int_{\mathbf{z}}p(\mathbf{x}, \mathbf{z})\mathrm{d}\mathbf{z}=\int_{\mathbf{z}} p(\mathbf{z}) p(\mathbf{x} | \mathbf{z})\mathrm{d}\mathbf{z}=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)</script><p>在隐变量 $\mathbf{z}$ 的存在之下，偏差变量 $h$ 的概率可以表示为联合概率对隐变量的边缘化：</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(h\mathbf{|x})& =\int_{\mathbf{z}}p(h, \mathbf{z}|\mathbf{x})\mathrm{d}\mathbf{z}\\
注意区分概率，和ｘ取值，这个式子是错的
\\
p(h\mathbf{|x})& =\int_{\mathbf{z}} p(h|\mathbf{z}) p(\mathbf{z} | \mathbf{x})\mathrm{d}\mathbf{z} \\
& =\sum_{k=1}^{K} p(h|z_{k}=1)p(z_{k}=1 | \mathbf{x})
\end{aligned}</script><p>因此求解函数 $p(h\mathbf{|x})$ 的问题转变成了求解有限维隐变量偏差分布 $ p(h|\mathbf{z})$ 的问题。另一个未知量$p(\mathbf{z} | \mathbf{x})$可由贝叶斯公式得到：</p>
<script type="math/tex; mode=display">
p(\mathbf{z} | \mathbf{x})=\frac{p(\mathbf{x} | \mathbf{z})p( \mathbf{z})}{p(\mathbf{x})}={\frac{ \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{k}, \boldsymbol{\Sigma}_{k}\right) \prod_{k=1}^{K} \pi_{k}^{z_{k}}}{\sum_{j=1}^{K} \pi_{j} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{j}, \mathbf{\Sigma}_{j}\right)}}</script><p>令$\gamma\left(z_{n k}\right)= p\left(z_{k}=1 | \mathbf{x}_n\right)$，那么：</p>
<script type="math/tex; mode=display">
\gamma\left(z_{n k}\right)=\frac{\pi_{k} \mathcal{N}\left(\mathbf{x}_{n} | \boldsymbol{\mu}_{k}, \boldsymbol{\Sigma}_{k}\right)}{\sum_{j=1}^{K} \pi_{j} \mathcal{N}\left(\mathbf{x}_{n} | \boldsymbol{\mu}_{j}, \mathbf{\Sigma}_{j}\right)}</script><p>令 $w_1=p(h|z_{k}=1)$<strong>这里错误</strong> , $\mathbf{w}=[w_1, w_2, …, w_k]^{\top}$ ， 则：</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(h\mathbf{|x}) &=\sum_{k=1}^{K} w_k \gamma\left(z_{k}\right)\\ 不对
\end{aligned}</script><p>此时，求解 $\mathbf{h}\in \mathbb{R}^{ns}$ 的问题，转换成了求解 $\mathbf{w}\in \mathbb{R}^{K}$ 如下，求解难度大大降低。</p>
<h3 id="3-求解隐变量偏差函数"><a href="#3-求解隐变量偏差函数" class="headerlink" title="3 求解隐变量偏差函数"></a>3 求解隐变量偏差函数</h3><h4 id="3-1-以条件分布算子的HS范数定义损失函数"><a href="#3-1-以条件分布算子的HS范数定义损失函数" class="headerlink" title="3.1 以条件分布算子的HS范数定义损失函数"></a>3.1 以条件分布算子的HS范数定义损失函数</h4><p>因此以条件分布距离最近为约束，优化参数  $\mathbf{w}$：</p>
<script type="math/tex; mode=display">
\mathbf{w}=\arg \min _{ \mathbf{w}\in \mathbb{R}^{K}} Dist[(p(\mathbf{y}_s^{new}|\mathbf{X}_s) ,p(\mathbf{y}_t|\mathbf{X}_t) ]</script><p>其中 $\mathbf{y}_{s}^{new}=\mathbf{y}_{s}+\mathbf{\Gamma}_s\mathbf{w}$, 式中矩阵 $\Gamma_s\in\mathbb{R}^{n_s\times K}$ 的每个元素为 $\gamma(z_{n k})=p(z_k=1 | \mathbf{x}_s^n)$ ， $\mathbf{w}\in\mathbb{R}^{K\times 1}$。</p>
<p>为了更方便估计条件分布，我们可以将其嵌入至再生核希尔伯特空间中。条件分布$P_{Y | {X}}$ 可以嵌入为算子$\mathcal{U}_{Y | X}: \mathscr{H} \rightarrow \mathscr{G}$ ，具体定义为 $\mathcal{U}_{Y | X}:=\mathcal{C}_{Y X} \mathcal{C}_{X X}^{-1}$， 其中 $\mathcal{C}_{Y X}$ 和  $\mathcal{C}_{Y X}$ 分别是交叉方差算子和自方差算子，即有：</p>
<script type="math/tex; mode=display">
\begin{array}
1 \mathcal{U}_{Y | X}&=\mathcal{C}_{Y X} \mathcal{C}_{X X}^{-1} \\
&=\mathbb{E}_{Y X}[\Psi(Y) \otimes \Phi(X)]\mathbb{E}_{Y X}^{-1}[\Phi(x) \otimes \Phi(X)]
\end{array}</script><p>对于给定观测值 $\mathbf{X_t,y_t}$，条件嵌入算子的经验估计为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\hat{\mathcal{U}}_{\mathbf{y}_{t} | \mathbf{X}_{t}}&=\frac{1}{n_t}\sum_{i=1}^{n_t} \varphi(y_{i}^{t})  \phi(\mathbf{x}_{i}^{t})\frac{1}{n_t}\sum_{i=1}^{n_t} [\phi(\mathbf{x}_{i}^{t})  \phi(\mathbf{x}_{i}^{t})+\lambda \mathbf{I}]^{-1} \\
&=\Psi\left(\mathbf{y}_{t}\right)\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+n_t\lambda \mathbf{I}\right)^{-1} \phi^{\top}\left(\mathbf{X}_{t}\right)
\end{aligned}</script><p>其中$\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}$为对应核矩阵。同理，对于条件分布$p(\mathbf{y}_s^{new}|\mathbf{X}_s)$的经验估计为:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\hat{\mathcal{U}}_{\mathbf{y}_s^{new} | \mathbf{X}_{s}}&=\frac{1}{n_s}\sum_{i=1}^{n_s} \varphi(y_{i}^{s})  \phi(\mathbf{x}_{i}^{s})\frac{1}{n_s}\sum_{i=1}^{n_s} [\phi(\mathbf{x}_{i}^{s})  \phi(\mathbf{x}_{i}^{s})+\lambda \mathbf{I}]^{-1} \\
&=\psi\left(\mathbf{y}_s^{new}\right)\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+n_s\lambda \mathbf{I}\right)^{-1} \phi^{\top}\left(\mathbf{X}_{s}\right)
\end{aligned}</script><p>至此，条件分布距离衡量函数定义为：</p>
<script type="math/tex; mode=display">
Dist[(p(\mathbf{y}_s^{new}|\mathbf{X}_s) ,p(\mathbf{y}_t|\mathbf{X}_t) ]=\left\|\hat{\mathcal{U}}\left[P_{\mathbf{y}_{s}^{new}| \mathbf{X}_{s}} \right]-\hat{\mathcal{U}}\left[P_{\mathbf{y}_{t} | \mathbf{X}_{t}}\right]\right\|_{HS}^{2}</script><p>此时损失函数定义为：</p>
<script type="math/tex; mode=display">
J(\mathbf{w})=\left\|\hat{\mathcal{U}}\left[P_{\mathbf{y}_{s}^{new}| \mathbf{X}_{s}} \right]-\hat{\mathcal{U}}\left[P_{\mathbf{y}_{t} | \mathbf{X}_{t}}\right]\right\|_{HS}^{2}+\lambda_c\mathbf{w}^{\top}\mathbf{w}</script><h4 id="3-2-损失函数求导及优化"><a href="#3-2-损失函数求导及优化" class="headerlink" title="3.2 损失函数求导及优化"></a>3.2 损失函数求导及优化</h4><p>因此最终损失函数表示为：</p>
<script type="math/tex; mode=display">
J=\left\|\Psi\left(\mathbf{y}_{s}^{new}\right)\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+\lambda \mathbf{I}\right)^{-1} \Phi^{\top}\left(\mathbf{X}_{s}\right)-\Psi\left(\mathbf{y}_{t}\right)\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+\lambda \mathbf{I}\right)^{-1} \Phi^{\top}\left(\mathbf{X}_{t}\right)\right\|^{2}+\lambda_c\mathbf{w}^{\top}\mathbf{w}</script><p>将其展开为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
J&=\left\|\Psi\left(\mathbf{y}_{s}^{new}\right)\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+\lambda \mathbf{I}\right)^{-1} \Phi^{\top}\left(\mathbf{X}_{s}\right)-\Psi\left(\mathbf{y}_{t}\right)\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+\lambda \mathbf{I}\right)^{-1} \Phi^{\top}\left(\mathbf{X}_{t}\right)\right\|^{2}+\lambda_c\mathbf{w}^{\top}\mathbf{w}\\
&= A+B-2C + \lambda_c\mathbf{w}^{\top}\mathbf{w}\\
\end{aligned}</script><p>其中：</p>
<script type="math/tex; mode=display">
\begin{aligned}
A&=\operatorname{Tr}\left\{\Phi\left(\mathbf{X}_{s}\right)\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+n_s\lambda \mathbf{I}\right)^{-1} \tilde{\mathbf{K}}\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+ n_s\lambda \mathbf{I}\right)^{-1} \Phi^{\top}\left(\mathbf{X}_{s}\right)\right\}\\
&=\operatorname{Tr}\left\{\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+n_s\lambda \mathbf{I}\right)^{-1} \tilde{\mathbf{K}}\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+ n_s\lambda \mathbf{I}\right)^{-1} \mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}\right\}\\
B&=\operatorname{Tr}\left\{\Phi\left(\mathbf{X}_{t}\right)\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+n_t\lambda \mathbf{I}\right)^{-1} \tilde{\mathbf{K}}^t\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+ n_t\lambda \mathbf{I}\right)^{-1} \Phi^{\top}\left(\mathbf{X}_{t}\right)\right\}\\
&=\operatorname{Tr}\left\{\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+n_t\lambda \mathbf{I}\right)^{-1} \tilde{\mathbf{K}}^t\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+ n_t\lambda \mathbf{I}\right)^{-1} \mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}\right\}\\
C&=\operatorname{Tr}\left\{\Phi\left(\mathbf{X}_{s}\right)\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+n_s\lambda \mathbf{I}\right)^{-1} \tilde{\mathbf{K}}^c\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+n_t \lambda \mathbf{I}\right)^{-1} \Phi^{\top}\left(\mathbf{X}_{t}\right)\right\}\\
&=\operatorname{Tr}\left\{\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+n_s\lambda \mathbf{I}\right)^{-1} \tilde{\mathbf{K}}^c\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+ n_t\lambda \mathbf{I}\right)^{-1} \mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{s}}\right\}
\end{aligned}</script><p>其中$\tilde{\mathbf{K}}=\mathbf{K}_{\mathbf{y}_{s}^{new} \mathbf{y}_{t}^{new}}$，$\tilde{\mathbf{K}}^c=\mathbf{K}_{\mathbf{y}_{s}^{new} \mathbf{y}_{t}}$，$\tilde{\mathbf{K}}^t=\mathbf{K}_{\mathbf{y}_{t} \mathbf{y}_{t}}$，$\tilde{\mathbf{K}}^t$为常数，求导时忽略。此时$L$对 $\mathbf{w}$的导数为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
 \frac{\partial J}{\partial \tilde{\mathbf{K}}}&=\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+\lambda \mathbf{I}\right)^{-1} \mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}^{\top}\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+\lambda \mathbf{I}\right)^{-1}\\
\frac{\partial J}{\partial \tilde{\mathbf{K}}^c}&=\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+\lambda \mathbf{I}\right)^{-1} \mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{s}}^{\top}\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+\lambda \mathbf{I}\right)^{-1}\\
\frac{\partial J}{\partial \mathbf{w}}&=\operatorname{Tr}\left[\left(\frac{\partial L}{\partial \tilde{\mathbf{K}}}\right)^{\top}\left(\frac{\partial \tilde{\mathbf{K}}}{\partial \mathbf{w}}\right)\right]-2\operatorname{Tr}\left[\left(\frac{\partial L}{\partial \tilde{\mathbf{K}}_{c}}\right)^{\top}\left(\frac{\partial \tilde{\mathbf{K}}^{c}}{\partial \mathbf{w}}\right)\right]+2\lambda_c\mathbf{w}\\
&=\operatorname{Tr}\left[\left(\frac{\partial L}{\partial \tilde{\mathbf{K}}}\right)^{\top}\left(\tilde{\mathbf{K}} \odot \mathbf{D}\right)\right]-2\operatorname{Tr}\left[\left(\frac{\partial L}{\partial \tilde{\mathbf{K}}^{c}}\right)^{\top}\left(\tilde{\mathbf{K}}_{c} \odot \mathbf{E}\right)\right]+2\lambda_c\mathbf{w}\\
\left[\mathbf{D}\right]_{i j}&=-\frac{1}{\sigma^{2}}\left(\mathbf{y}_{i}^{n e w}-\mathbf{y}_{j}^{n e w}\right)\left\{\mathbf{\Gamma}_{i}^{s} \mathbf{I}(i=p)-\mathbf{\Gamma}_{j}^{s} \mathbf{I}(j=p)\right\}\\
\left[\mathbf{E}\right]_{i j}&=-\frac{1}{\sigma^{2}}\left(\mathbf{y}_{i}^{n e w}-\mathbf{y}_{j}^{t L}\right) \mathbf{\Gamma}_{i}^{s} \mathbf{I}(i=p)
\end{aligned}</script><p>此时可以梯度下降法求解$\mathbf{w}$ </p>
<h3 id="4-泛化边界"><a href="#4-泛化边界" class="headerlink" title="4. 泛化边界"></a>4. 泛化边界</h3><p>我们将给出基于稳定性分析泛化误差，首先引入定理1：</p>
<p><strong>定理1</strong>：<em>对于未知分布$D$ 中采样的训练集：</em></p>
<script type="math/tex; mode=display">
S=\left\{z_{1}=\left(x_{1}, y_{1}\right), \ldots, z_{m}=\left(x_{m}, y_{m}\right)\right\}</script><p><em>设 $F$ 是一个具有核 $k$ 的再生核希尔伯特空间，且 $\forall x \in X, k(x, x) \leq \kappa^{2}&lt;\infty$ ，设 $l$ 关于 $F$ 是 $\sigma$ -admissible的，且损失函数 $l\leq4M^2 $ 。学习算法$A_s$ 定义为：</em></p>
<script type="math/tex; mode=display">
A_{S}=\arg \min _{f \in \mathcal{H}} \frac{1}{m} \sum_{i=1}^{m} l\left(f, z_{i}\right)+\lambda\|f\|_{k}^{2}</script><p><em>则学习算法对于损失函数 $l$ 的稳定边界为：</em></p>
<script type="math/tex; mode=display">
\beta \leq \frac{\sigma^{2} \kappa^{2}}{2 \lambda m}</script><p><em>令$R=\mathbb{E}_{z}\left[l\left(A_{S}, z\right)\right]$ 为算法泛化误差 ，$R_{e m p}=\frac{1}{m} \sum_{i=1}^{m} l\left(A_{S}, z_{i}\right) $ 为算法的经验误差，则至少以概率 $1-\delta$ ，使以下不等式成立：</em></p>
<script type="math/tex; mode=display">
R \leq R_{e m p}+\frac{\sigma^{2} \kappa^{2}}{\lambda m}+\left(\frac{2 \sigma^{2} \kappa^{2}}{\lambda}+4 M^{2}\right) \sqrt{\frac{\ln (1 / \delta)}{2 m}}</script><p>令 $\tilde{z}_{i}=\left(\tilde{\mathbf{x}}_{i}, \tilde{y}_{i}\right) \in(\tilde{\mathbf{X}}, \tilde{\mathbf{y}})$ ，其中 $\tilde{\mathbf{X}}=\mathbf{X}_s\cup\mathbf{X}_t$，  $\tilde{\mathbf{y}}=\mathbf{y}_s^{new}\cup\mathbf{y}_t$ ，定义最终目标模型为在融合数据上$\tilde{z}_{i}$ 上训练的模型：</p>
<p><strong>定理2</strong>：设$| \hat{\mathcal{U}}\left[P_{\mathbf{y}_{s}^{new} | \mathbf{X}_{s}}\right]-\hat{\mathcal{U}}\left[P_{\mathbf{y}_{t} | \mathbf{X}_{s}}\right] |\leq\epsilon$ ，$l_s\leq4M_s^2 $ ，$l_h\leq4M_h^2 $ ，则至少以概率 $1-\delta$ ，使以下不等式成立：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\left|\frac{1}{n_s+n_t} \sum_{i=1}^{n_s+n_t} l\left(f_t, \tilde{z}_{i}\right)-E_{z^{t}}\left[l\left(f_t, z^{t}\right)\right]\right| \\
&\leq 4 M\left(\epsilon \kappa+C\left(\lambda_{c}^{1 / 2}+\left(n_{l} \lambda_{c}\right)^{-1 / 2}\right)\right)\\
&+ \frac{\sigma^{2} \kappa^{2}}{\lambda_{t}(n_s+n_t)}+\left(\frac{2 \sigma^{2} \kappa^{2}}{\lambda_{t}}+4 M^{2}\right) \sqrt{\frac{\ln (1 / \delta)}{2(n_s+n_t)}}
\end{aligned}</script><h3 id="5-曲线实验"><a href="#5-曲线实验" class="headerlink" title="5. 曲线实验"></a>5. 曲线实验</h3><p>本次不再加入仿真曲线验证，直接找三个数据集验证：</p>
<p><img src="/2020/01/09/GMMTL_2020/Fig2 GMMTL.svg" style="zoom:67%;"></p>

          
        
      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tangmeii.cn/2019/12/27/GMMTL_Z/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gengxiang">
      <meta itemprop="description" content="某航空人">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tangmeii_Sites">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/12/27/GMMTL_Z/" class="post-title-link" itemprop="http://tangmeii.cn/index.html">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-12-27 09:27:14" itemprop="dateCreated datePublished" datetime="2019-12-27T09:27:14+08:00">2019-12-27</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2020-01-09 17:15:11" itemprop="dateModified" datetime="2020-01-09T17:15:11+08:00">2020-01-09</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<hr>
<h1 id="2019年12月31日-方案示例"><a href="#2019年12月31日-方案示例" class="headerlink" title="2019年12月31日 方案示例"></a><strong>2019年12月31日</strong> 方案示例</h1><p>[TOC]</p>
<h3 id="0-七个问题"><a href="#0-七个问题" class="headerlink" title="0.七个问题"></a>0.七个问题</h3><p><strong>背景</strong>：数据驱动方法广泛应用于各个领域，而且需要标签数据。制造领域许多问题的标签数据获取成本非常高，因此一个重要的思路的就是迁移学习，而制造领域中常见的一类问题是条件分布偏差的回归问题，几乎没有得到关注。</p>
<p><strong>问题：</strong>如何解决条件差异的回归迁移问题</p>
<p><strong>现状</strong>：如下</p>
<ul>
<li>基于样本权重的，本质上不适用整体条件分布差异，仅用于局部 (instance based)</li>
<li>基于目标数据求映射 (instance based)</li>
<li>基于目标数据求偏差函数 (model based)</li>
<li>基于目标数据更新模型参数 (parameter based)</li>
</ul>
<p><strong>GAP</strong>:  上述方法实际使用难以求解，如同鸡肋。</p>
<p><strong>难点</strong>：以上三类解求解难度等同于直接求解目标模型。目标数据数量少，即目标模型不足以充分构建，因此把直接求解目标模型，转换成求解映射、残差函数、模型参数，依旧困难。</p>
<p><strong>创新点</strong>：利用边缘分布相同条件，引入隐变量，使得难以求解的函数转化为有限个隐变量参数。以近似方式，增强了可解性。</p>
<p><strong>方案</strong>：</p>
<ul>
<li>用K个高斯模型混合估计$D_s$的分布</li>
<li>用混合高斯模型采样得到初始目标数据</li>
<li>把目标模型求解转换为偏差模型求解问题</li>
<li>把偏差模型求解，转化为有限个($K$)个隐变量参数问题，可解了</li>
</ul>
<p><strong>验证</strong>：$ResTL$是一种子情况，因此验证可控。通过在不少于3个数据集上验证方法的效果。</p>
<h3 id="1-问题定义"><a href="#1-问题定义" class="headerlink" title="1.问题定义"></a>1.问题定义</h3><p>假设==已有==源回归任务包含大量训练数据 $\mathcal{D}_S=\left\{\left(\mathbf{x}_1^s,y_1^s\right),\ldots,\left(\mathbf{x}_{n_s}^s,y_{n_s}^s\right)\right\}$ , 其中 $\mathbf{x}_i^s\in\mathcal{X}_S$ 是源数据特征， $y_i^s\in\mathcal{Y}_S$ 是源数据标签，回归任务因此标签为连续变量。同时有另一个相似的回归任务，仅有少量的标签数据 $\mathcal{D}_T=\left\{\left(\mathbf{x}_1^t,y_1^t\right),\ldots,\left(\mathbf{x}_{n_t}^t,y_{n_t}^t\right)\right\}$ , 其中 $\mathbf{x}_i^t  \in \mathcal{X}_T$ 是输入， $y_i^t\in\mathcal{Y}_T$ 对应的输出。此处所关注的是两个回归任务的条件偏移场景，即假设边缘分布相同 ​，而条件分布不同，即$p\left(y_s\middle|\mathbf{x}_s\right)\neq p\left(y_t\middle|\mathbf{x}_t\right)$。</p>
<p>为了后面更加清晰描述，此处定义清楚两数据集的所需表示：</p>
<p>源数据    $\mathcal{D}_s$, 包含输入特征矩阵 ${\mathbf{X}}_s\in\mathbb{R}^{n_s\times d}$ 和输出标签向量 ${\mathbf{y}}_s\in\mathbb{R}^{n_s\times 1}$ :</p>
<script type="math/tex; mode=display">
\mathbf{X}_{s}=\left[\mathbf{x}_{1}^{s}, \mathbf{x}_{2}^{s}, \ldots, \mathbf{x}_{n_{s}}^{s}\right]^{\top}, \mathbf{y}_{s}=\left[y_{1}^{s}, y_{2}^{s}, \ldots, y_{n_{s}}^{s}\right]^{\top}</script><p>目标数据 $\mathcal{D}_t$, 包含输入特征矩阵 ${\mathbf{X}}_t\in\mathbb{R}^{n_t\times d}$ 和输出标签向量 ${\mathbf{y}}_t\in\mathbb{R}^{n_t\times 1}$ :</p>
<script type="math/tex; mode=display">
\mathbf{X}_{t}=\left[\mathbf{x}_{1}^{t}, \mathbf{x}_{2}^{t}, \ldots, \mathbf{x}_{n_{t}}^{t}\right]^{\top}, \mathbf{y}_{t}=\left[y_{1}^{t}, y_{2}^{t}, \ldots, y_{n_{t}}^{t}\right]^{\top}</script><h3 id="2-问题转化"><a href="#2-问题转化" class="headerlink" title="2. 问题转化"></a>2. 问题转化</h3><p><img src="/2019/12/27/GMMTL_Z/Fig1 Illustration of conditional distribution shift.svg" style="zoom:60%;"></p>
<h4 id="2-1-引出偏差分布"><a href="#2-1-引出偏差分布" class="headerlink" title="2.1 引出偏差分布"></a>2.1 引出偏差分布</h4><p>首先假设源模型和目标模型分别为$f_s(\mathbf{x})$ 和 $f_t(\mathbf{x})$，观测标签值表示为：</p>
<script type="math/tex; mode=display">
y_s=f_s(\mathbf{x})+\epsilon ,\ \ y_t=f_s(\mathbf{x})+\epsilon</script><p>由于源数据数量充分，因此认为$f_s(\mathbf{x})$ 是已知函数， $f_t(\mathbf{x})$是未知函数，待求。</p>
<p>其中噪声服从均值0，方差$\sigma_n^2$ 的高斯分布，即：</p>
<script type="math/tex; mode=display">
\varepsilon \sim \mathcal{N}\left(0, \sigma_{n}^{2}\right)</script><p>因此，条件概率可以表示为：</p>
<script type="math/tex; mode=display">
p(y_s|\mathbf{x})=\mathcal{N}\left(f_s(\mathbf{x}), \sigma_{n}^{2}\right)</script><script type="math/tex; mode=display">
p(y_t|\mathbf{x})=\mathcal{N}\left(f_t(\mathbf{x}), \sigma_{n}^{2}\right)</script><p>带入所有的样本，表示为：</p>
<script type="math/tex; mode=display">
p(\mathbf{y}_s|\mathbf{X}_s)=\mathcal{N}\left(f_s(\mathbf{X}_s), \sigma_{n}^{2}\right)</script><script type="math/tex; mode=display">
p(\mathbf{y}_t|\mathbf{X}_t)=\mathcal{N}\left(f_t(\mathbf{X}_t), \sigma_{n}^{2}\right)</script><p>在整个特征空间范围内，将条件分布差异定义为偏差项(<code>discrepance</code>)定义为 $h(\mathbf{x})$，由于期望取值为连续变量，因此残差项总可以表示为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(h|\mathbf{x}) &=\  p(y_t|\mathbf{x})-p(y_t|\mathbf{x})\\
 &= \mathcal{N}\left(f_t(\mathbf{x}), \sigma_{n}^{2}\right)-\mathcal{N}\left(f_s(\mathbf{x}), \sigma_{n}^{2}\right) \\
 &=\mathcal{N}(f_t(\mathbf{x})-f_s(\mathbf{x}),2\sigma_{n}^{2})
\end{aligned}</script><p>因此迁移问题转换成求解偏差条件分布 $p(h|\mathbf{x})$， 由于$f_s(\mathbf{x})$ 是已知的，对于已有的目标数据 $\mathcal{D}_T$，其可观测偏差值为：</p>
<script type="math/tex; mode=display">
\mathbf{h}_t=\mathbf{y}_t-f_s(\mathbf{X}_t)</script><p>到此位置，问题可以表示为，已知观测值 $\mathbf{h}_t, \mathbf{X}_t$, 来求解分布 $p(h|\mathbf{x}_<em>)$， 若目标数据的数量$\mathcal{D}_T$ 足够大，那么 $p(h|\mathbf{x}_</em>)$ 可以直接估计出来，然而迁移学习所面临的场景，就是 $\mathcal{D}_T$ 数量很小的情况。因此 $p(h|\mathbf{x}_<em>)$ 无法直接求解，<em>*在此我们要利用边缘分布相同条件，引入隐变量，使得这个原本不可解的问题，变得可解</em></em>。</p>
<h4 id="2-2-高斯混合模型描述特征空间分布"><a href="#2-2-高斯混合模型描述特征空间分布" class="headerlink" title="2.2 高斯混合模型描述特征空间分布"></a>2.2 高斯混合模型描述特征空间分布</h4><p>考虑到 $p(\mathbf{x}_s)=p(\mathbf{x}_t)$ ，因此我们用一组$K$维混合高斯分布来描述两个领域的特征空间分布：</p>
<script type="math/tex; mode=display">
p(\mathbf{x})=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)</script><p>即$p(\mathbf{x}_s)=p(\mathbf{x}_t)=p(\mathbf{x})$，其中$\sum_{k=1}^{K} \pi_{k}=1$ 为高斯混合模型的混合系数。此时，为了描述变量对与每个高斯高斯分布的归属情况， 我们引入变量 $\mathbf{z}\in\mathbb{R}^{K\times 1}$ ，向量 $\mathbf{z}$ 只有一个元素为1，其他元素都为0，也就是$\sum_{k} z_{k}=1$， 因此向量 $\mathbf{z}$ 共有 $K$ 种状态，对于样本 $\mathbf{x}$ 归属于第 $k$ 个高斯分布的情况，即 $z_k=1$，其概率可以表示为高斯混合模型的混合系数，即$p\left(z_{k}=1\right)=\pi_{k}$。由于向量中只有一个量为1，其他都为0，那么向量 $\mathbf{z}$ 的概率可以表示为 $p(\mathbf{z})=\prod_{k=1}^{K} \pi_{k}^{z_{k}}$。</p>
<p>在隐变量 $\mathbf{z}$ 的存在之下，观测样本$\mathbf{x}$的概率可以表示为：</p>
<script type="math/tex; mode=display">
p(\mathbf{x})=\int_{\mathbf{z}}p(\mathbf{x}, \mathbf{z})\mathrm{d}\mathbf{z}=\int_{\mathbf{z}} p(\mathbf{z}) p(\mathbf{x} | \mathbf{z})\mathrm{d}\mathbf{z}=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)</script><p>在隐变量 $\mathbf{z}$ 的存在之下，偏差变量 $h$ 的概率可以表示为联合概率对隐变量的边缘化：</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(h\mathbf{|x})& =\int_{\mathbf{z}}p(h, \mathbf{z}|\mathbf{x})\mathrm{d}\mathbf{z}\\
p(h\mathbf{|x})& =\int_{\mathbf{z}} p(h|\mathbf{z}) p(\mathbf{z} | \mathbf{x})\mathrm{d}\mathbf{z} \\
& =\sum_{k=1}^{K} p(h|z_{k}=1)p(z_{k}=1 | \mathbf{x})
\end{aligned}</script><p>因此求解函数 $p(h\mathbf{|x})$ 的问题转变成了求解有限维隐变量偏差分布 $ p(h|\mathbf{z})$ 的问题。另一个未知量$p(\mathbf{z} | \mathbf{x})$可由贝叶斯公式得到：</p>
<script type="math/tex; mode=display">
p(\mathbf{z} | \mathbf{x})=\frac{p(\mathbf{x} | \mathbf{z})p( \mathbf{z})}{p(\mathbf{x})}={\frac{ \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{k}, \boldsymbol{\Sigma}_{k}\right) \prod_{k=1}^{K} \pi_{k}^{z_{k}}}{\sum_{j=1}^{K} \pi_{j} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{j}, \mathbf{\Sigma}_{j}\right)}}</script><p>令$\gamma\left(z_{n k}\right)= p\left(z_{k}=1 | \mathbf{x}_n\right)$，那么：</p>
<script type="math/tex; mode=display">
\gamma\left(z_{n k}\right)=\frac{\pi_{k} \mathcal{N}\left(\mathbf{x}_{n} | \boldsymbol{\mu}_{k}, \boldsymbol{\Sigma}_{k}\right)}{\sum_{j=1}^{K} \pi_{j} \mathcal{N}\left(\mathbf{x}_{n} | \boldsymbol{\mu}_{j}, \mathbf{\Sigma}_{j}\right)}</script><p>令 $w_1=p(h|z_{k}=1)$ , $\mathbf{w}=[w_1, w_2, …, w_k]^{\top}$ ， 则：</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(h\mathbf{|x}) &=\sum_{k=1}^{K} w_k \gamma\left(z_{k}\right)\\
\end{aligned}</script><p>如下，将探索如何求解$\mathbf{w}$。</p>
<h3 id="3-求解隐变量偏差函数"><a href="#3-求解隐变量偏差函数" class="headerlink" title="3 求解隐变量偏差函数"></a>3 求解隐变量偏差函数</h3><p>关于偏差函数  $w(\mathbf{\mathbf{z}})$，以下给出三种解法。</p>
<h4 id="3-1-Method-A-1-最小平方误差求解"><a href="#3-1-Method-A-1-最小平方误差求解" class="headerlink" title="3.1 Method A-1: 最小平方误差求解"></a>3.1 Method A-1: 最小平方误差求解</h4><p>已知观测值 $\mathbf{h}_t, \mathbf{X}_t$, 来求解分布 $p(h|\mathbf{x}_*)$，的问题，已转化为求解$p(h\mathbf{|z})$ 即求解$\mathbf{w}$。定义损失函数：</p>
<script type="math/tex; mode=display">
\begin{aligned}
J(\mathbf{w})& =\sum_{n=1}^{n_t}\sum_{k=1}^{K} \{w_k p(z_{k}=1 | \mathbf{x}_n^t)-(y_n^t-f_s(\mathbf{x}_n^t))\}^{2} + \sum_{k=1}^{K}w_k^2\\
J(\mathbf{w})&= (\Gamma\mathbf{w}-\mathbf{h}_t)^\top(\Gamma\mathbf{w}-\mathbf{h}_t)+\lambda\mathbf{w}^{\top}\mathbf{w}
\end{aligned}</script><p>式子中矩阵 $\Gamma\in\mathbb{R}^{n_t\times K}$ 的每个元素为$\gamma(z_{n k})=p(z_k=1 | \mathbf{x}_t^n)$ , $\mathbf{w}\in\mathbb{R}^{K\times 1}$。</p>
<p>损失函数对$\mathbf{w}$求导，再令导数等于零：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{d J}{d\mathbf{w}}& =\frac{d(\Gamma\mathbf{w}-\mathbf{h}_t)^\top(\Gamma\mathbf{w}-\mathbf{h}_t)+\lambda\mathbf{w}^{\top}\mathbf{w}}{d\mathbf{w}} \\
&=\frac{d\left(\mathbf{w}^{\top} \Gamma^{\top}\Gamma \mathbf{w}-\mathbf{h}_t^{\top} \Gamma \mathbf{h}_t-\mathbf{w}^{\top} \Gamma^{\top} \mathbf{h}_t+\mathbf{h}_t^{\top} \mathbf{h}_t +\lambda\mathbf{w}^{\top}\mathbf{w}\right)}{d \mathbf{w}} \\
& =\Gamma^{\top} \Gamma \mathbf{w}+\Gamma^{\top} \Gamma \mathbf{w}-\Gamma^{\top} \mathbf{h}_t-\Gamma^{\top} \mathbf{h}_t+2\lambda\mathbf{w} =0 \\
\end{aligned} \tag{2}</script><p>因此可以解得：</p>
<script type="math/tex; mode=display">
\mathbf{w}=(\mathbf{\Gamma}^{\top}\mathbf{\Gamma}+\lambda\mathbf{I})^{-1}\mathbf{\Gamma}^{\top}\mathbf{h}_t</script><h4 id="3-1-Method-A-1-Bayesian"><a href="#3-1-Method-A-1-Bayesian" class="headerlink" title="3.1 Method A-1 Bayesian"></a>3.1 Method A-1 Bayesian</h4><p>已知观测值 $\mathbf{h}_t, \mathbf{X}_t$, 来求解分布 $p(h|\mathbf{x}_*)$，首先有：</p>
<script type="math/tex; mode=display">
p(h|\mathbf{x})\sim\mathcal{N}(\sum_{k=1}^{K} w_k \gamma\left(z_{k}\right),2\sigma_{n}^{2})</script><p>对于参数$\mathbf{w}$，我们假设其先验为：</p>
<script type="math/tex; mode=display">
\mathbf{w} \sim \mathcal{N}\left(\mathbf{0}, \Sigma_{p}\right)</script><p>那么其后验概率为：</p>
<script type="math/tex; mode=display">
p(\mathbf{w} | \mathbf{X}_t, \mathbf{h}_t)=\frac{p(\mathbf{h}_t| \mathbf{X}_t,\mathbf{w} )p( \mathbf{w})}{p(\mathbf{h}_t|\mathbf{X}_t)}</script><p>可以解得：</p>
<script type="math/tex; mode=display">
p(\mathbf{w} | \mathbf{X}_t, \mathbf{h}_t) \sim \mathcal{N}\left(\frac{1}{\sigma_{n}^{2}} \mathbf{A}^{-1} \mathbf{X}_t \mathbf{h}_t, \mathbf{A}^{-1}\right)</script><p>其中$\mathbf{A}=\sigma_{n}^{-2}\mathbf{X}_t \mathbf{X}_t^{\top}+\Sigma_{p}^{-1}$ ，此时，对于观测点$\mathbf{x}_*$， 其偏差分布为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
p\left(h_{*} | \mathbf{x}_{*}, \mathbf{X}_t, \mathbf{h}_t\right) &=\int p\left(h_{*} | \mathbf{x}_{*}, \mathbf{w}\right) p(\mathbf{w} | \mathbf{X}_t, \mathbf{h}_t) d \mathbf{w}=\int \mathbf{x}_{*}^{\top} \mathbf{w} p(\mathbf{w} | \mathbf{X}_t, \mathbf{h}_t) d \mathbf{w} \\
&=\mathcal{N}\left(\frac{1}{\sigma_{n}^{2}} \mathbf{x}_{*}^{\top} \mathbf{A}^{-1} \mathbf{X}_t \mathbf{h}_t, \mathbf{x}_{*}^{\top} \mathbf{A}^{-1} \mathbf{x}_{*}\right)
\end{aligned}</script><h4 id="3-2-Method-B-Method-What"><a href="#3-2-Method-B-Method-What" class="headerlink" title="3.2 Method B: Method What?"></a>3.2 Method B: Method What?</h4><p>第二种思路没想好对应的什么理论。逆向思维思考问题，首先我有：</p>
<script type="math/tex; mode=display">
p(h\mathbf{|x})=\int_{\mathbf{z}} p(h|\mathbf{z}) p(\mathbf{z} | \mathbf{x})\mathrm{d}\mathbf{z}</script><p><strong>直观上的一组解法如下，不过我不知道为什么可以这么解：</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
p(h\mathbf{|z})=&\frac{\int_{\mathbf{x}}p(h\mathbf{|x})p(\mathbf{x} | \mathbf{z})\mathrm{d}\mathbf{x}}{\int_{\mathbf{x}}p(\mathbf{x} | \mathbf{z})\mathrm{d}\mathbf{x}}

\end{aligned}</script><p>$w(\mathbf{z})$ 对应的是$K$ 个规则的偏差值，因此每个规则对应的偏差值可以表示为：</p>
<script type="math/tex; mode=display">
w_k=\frac{\sum_{n=1}^{n_t}h(\mathbf{x}_n^t)p(\mathbf{x}|z_{k}=1 )}{\sum_{n=1}^{n_t}p(\mathbf{x}_n^t|z_{k}=1 )}
=\frac{\sum_{n=1}^{n_t}h(\mathbf{x}_n^t) \mathcal{N}\left(\mathbf{x}_n^t | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)}{\sum_{n=1}^{n_t} \mathcal{N}\left(\mathbf{x}_n^t | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)}</script><p>即为：</p>
<script type="math/tex; mode=display">
w_k=\frac{\sum_{n=1}^{n_t}(f_s(\mathbf{x}_n^t)-y^t_n)\mathcal{N}\left(\mathbf{x}_n^t | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)}{\sum_{n=1}^{n_t} \mathcal{N}\left(\mathbf{x}_n^t | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)}</script><h4 id="3-3-Method-C-条件分布核适配"><a href="#3-3-Method-C-条件分布核适配" class="headerlink" title="3.3  Method C: 条件分布核适配"></a>3.3  Method C: 条件分布核适配</h4><p>参照CMU的论文，可以以适配条件分布核均值为约束，优化参数  $\mathbf{w}$，具体如下：</p>
<p>我们目标定义为最佳偏置函数应满足条件嵌入算子匹配，即损失函数定义为</p>
<script type="math/tex; mode=display">
L=\left\|\hat{\mathcal{U}}\left[P_{\mathbf{y}_{s}^{new}| X_{s}} \right]-\hat{\mathcal{U}}\left[P_{\mathbf{y}_{t} | X_{t}}\right]\right\|_\mathscr{H}^{2}+\lambda_c\mathbf{w}^{\top}\mathbf{w}</script><p>其中：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{s}^{new}=\mathbf{y}_{s}-h(\mathbf{X}_s)=\mathbf{y}_{s}-\mathbf{\Gamma}_s\mathbf{w}</script><p>式子中矩阵 $\Gamma_s\in\mathbb{R}^{n_s\times K}$ 的每个元素为 $\gamma(z_{n k})=p(z_k=1 | \mathbf{x}_s^n)$ ， $\mathbf{w}\in\mathbb{R}^{K\times 1}$。</p>
<p>条件嵌入算子表示为：</p>
<script type="math/tex; mode=display">
\hat{\mathcal{U}}\left[P_{Y | {X}}\right]=\Psi(Y)\left(K_{X X}+\lambda I\right)^{-1} \Phi^{\top}(X)</script><p>因此最终损失函数表示为：</p>
<script type="math/tex; mode=display">
L=\left\|\Psi\left(\mathbf{y}_{s}^{new}\right)\left(\mathbf{K}_{\mathbf{X}_{s} \mathbf{X}_{s}}+\lambda \mathbf{I}\right)^{-1} \Phi^{\top}\left(\mathbf{X}_{s}\right)-\Psi\left(\mathbf{y}_{t}\right)\left(\mathbf{K}_{\mathbf{X}_{t} \mathbf{X}_{t}}+\lambda \mathbf{I}\right)^{-1} \Phi^{\top}\left(\mathbf{X}_{t}\right)\right\|_\mathscr{H}^{2}+\lambda_c\mathbf{w}^{\top}\mathbf{w}</script><p>可以用梯度下降法求解 $\mathbf{w}$ 。</p>
<h3 id="4-泛化边界"><a href="#4-泛化边界" class="headerlink" title="4. 泛化边界"></a>4. 泛化边界</h3><p>基于稳定性分析泛化误差，首先有定理1：</p>
<p><strong>定理1</strong>：<em>对于未知分布$D$ 中采样的训练集：</em></p>
<script type="math/tex; mode=display">
S=\left\{z_{1}=\left(x_{1}, y_{1}\right), \ldots, z_{m}=\left(x_{m}, y_{m}\right)\right\}</script><p><em>设 $F$ 是一个具有核 $k$ 的再生核希尔伯特空间，且 $\forall x \in X, k(x, x) \leq \kappa^{2}&lt;\infty$ ，设 $l$ 关于 $F$ 是 $\sigma$ -admissible的，且损失函数 $l\leq4M^2 $ 。学习算法$A_s$ 定义为：</em></p>
<script type="math/tex; mode=display">
A_{S}=\arg \min _{f \in \mathcal{H}} \frac{1}{m} \sum_{i=1}^{m} l\left(f, z_{i}\right)+\lambda\|f\|_{k}^{2}</script><p><em>则学习算法对于损失函数 $l$ 的稳定边界为：</em></p>
<script type="math/tex; mode=display">
\beta \leq \frac{\sigma^{2} \kappa^{2}}{2 \lambda m}</script><p><em>令$R=\mathbb{E}_{z}\left[l\left(A_{S}, z\right)\right]$ 为算法泛化误差 ，$R_{e m p}=\frac{1}{m} \sum_{i=1}^{m} l\left(A_{S}, z_{i}\right) $ 为算法的经验误差，则至少以概率 $1-\delta$ ，使以下不等式成立：</em></p>
<script type="math/tex; mode=display">
R \leq R_{e m p}+\frac{\sigma^{2} \kappa^{2}}{\lambda m}+\left(\frac{2 \sigma^{2} \kappa^{2}}{\lambda}+4 M^{2}\right) \sqrt{\frac{\ln (1 / \delta)}{2 m}}</script><p><strong>条件核适配解法的泛化界</strong>。</p>
<p>定义源数据模型为数据 $z_{i}^s=\{\mathbf{x}_i^s, y_i^s\}$ 上训练的模型 $f_s$:</p>
<script type="math/tex; mode=display">
f_{s}=\arg \min _{f \in \mathcal{H}} \frac{1}{n_s} \sum_{i=1}^{n_s} l_s\left(f, z_{i}^s\right)+\lambda_s\|f\|_{k}^{2}</script><p>太麻烦了，这里的残差值是估计的，也要考虑。定义残差模型为数据 $z_{i}^h=\{\mathbf{x}_i^t, y_i^t\}$ 上训练的模型 $f_h$:</p>
<script type="math/tex; mode=display">
f_{h}=\arg \min _{f \in \mathcal{H}} \frac{1}{n_t} \sum_{i=1}^{n_t} l_h\left(f, z_{i}^h\right)+\lambda_h\|f\|_{k}^{2}</script><p>情况<strong>A</strong>: 定义最终目标模型为：$f_t = f_s + f_h$</p>
<p>情况<strong>B</strong>：令 $\tilde{z}_{i}=\left(\tilde{\mathbf{x}}_{i}, \tilde{y}_{i}\right) \in(\tilde{\mathbf{X}}, \tilde{\mathbf{y}})$ ，其中 $\tilde{\mathbf{X}}=\mathbf{X}_s\cup\mathbf{X}_t$，  $\tilde{\mathbf{y}}=\mathbf{y}_s^{new}\cup\mathbf{y}_t$ ，定义最终目标模型为在融合数据上$\tilde{z}_{i}$ 上训练的模型：</p>
<p><strong>定理2</strong>：设$| \hat{\mathcal{U}}\left[P_{\mathbf{y}_{s}^{new} | \mathbf{X}_{s}}\right]-\hat{\mathcal{U}}\left[P_{\mathbf{y}_{t} | \mathbf{X}_{s}}\right] |\leq\epsilon$ ，$l_s\leq4M_s^2 $ ，$l_h\leq4M_h^2 $ ，则至少以概率 $1-\delta$ ，使以下不等式成立：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\left|\frac{1}{n_s+n_t} \sum_{i=1}^{n_s+n_t} l\left(f_t, \tilde{z}_{i}\right)-E_{z^{t}}\left[l\left(f_t, z^{t}\right)\right]\right| \\
&\leq (4 M_s+4 M_h)\left(\epsilon \kappa+C\left(\lambda_{c}^{1 / 2}+\left(n_{l} \lambda_{c}\right)^{-1 / 2}\right)\right)\\
&+ \frac{\sigma^{2} \kappa^{2}}{\lambda_{s}n_s}+\left(\frac{2 \sigma^{2} \kappa^{2}}{\lambda_{s}}+4 M_s^{2}\right) \sqrt{\frac{\ln (1 / \delta)}{2n_s}}+ \frac{\sigma^{2} \kappa^{2}}{\lambda_{t}n_t}+\left(\frac{2 \sigma^{2} \kappa^{2}}{\lambda_{t}}+4 M_t^{2}\right) \sqrt{\frac{\ln (1 / \delta)}{2n_t}}
\end{aligned}</script><p><strong>证明</strong>：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\left|\frac{1}{n_s+n_t} \sum_{i=1}^{n_s+n_t} l\left(f_t, \tilde{z}_{i}\right)-E_{z^{t}}\left[l\left(f_t, z^{t}\right)\right]\right| \\
&\leq \left|\frac{1}{n_s+n_t} \sum_{i=1}^{n_s+n_t} l\left(f_t, \tilde{z}_{i}\right)-\frac{1}{n_s+n_t} \sum_{i=1}^{n_s+n_t} l\left(f_t, z_{i}^*\right)\right| \\
&+ \left|\frac{1}{n_s+n_t} \sum_{i=1}^{n_s+n_t} l\left(f_t, z_{i}^*\right)-E_{z^{t}}\left[l\left(f_t, z^{t}\right)\right]\right| \\
\end{aligned}</script><p>先看第二项，相当于$n_s+n_t$ 个样本的训练误差和测试误差，由于$f_t = f_s + f_h$， 有：$l\left(f_t, z_{i}^*\right)&lt;$</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\left|\frac{1}{n_s+n_t} \sum_{i=1}^{n_s+n_t} l\left(f_t, z_{i}^*\right)-E_{z^{t}}\left[l\left(f_t, z^{t}\right)\right]\right| \\
=&\left|\frac{1}{n_s+n_t}\left[ \sum_{i=1}^{n_s} l\left(f_t, z_{i}^*\right)+\sum_{i=1}^{n_t} l\left(f_t, z_{i}^*\right)\right]-E_{z^{t}}\left[l\left(f_t, z^{t}\right)\right]\right|  \\
=&\left|\frac{1}{n_s+n_t}\left[ \sum_{i=1}^{n_s} l\left(f_t, z_{i}^*\right)+\sum_{i=1}^{n_t} l\left(f_t, z_{i}^*\right)\right]-E_{z^{t}}\left[l\left(f_t, z^{t}\right)\right]\right|  \\
\end{aligned}</script><h3 id="5-曲线实验"><a href="#5-曲线实验" class="headerlink" title="5. 曲线实验"></a>5. 曲线实验</h3><p>sin曲线上实际测试如下，其中Method C的参数实在难调：</p>
<p><img src="/2019/12/27/GMMTL_Z/Fig2 GMMTL.svg" style="zoom:67%;"></p>

          
        
      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tangmeii.cn/2019/12/18/GMMTL/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gengxiang">
      <meta itemprop="description" content="某航空人">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tangmeii_Sites">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/12/18/GMMTL/" class="post-title-link" itemprop="http://tangmeii.cn/index.html">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-12-18 20:21:58" itemprop="dateCreated datePublished" datetime="2019-12-18T20:21:58+08:00">2019-12-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-12-27 09:27:22" itemprop="dateModified" datetime="2019-12-27T09:27:22+08:00">2019-12-27</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<hr>
<h1 id="2019年12月20日"><a href="#2019年12月20日" class="headerlink" title="2019年12月20日"></a><strong>2019年12月20日</strong></h1><p>[TOC]</p>
<h3 id="1-问题定义"><a href="#1-问题定义" class="headerlink" title="1. 问题定义"></a>1. 问题定义</h3><p>假设已有源回归任务包含大量训练数据 $\mathcal{D}_S=\left\{\left(\mathbf{x}_1^s,y_1^s\right),\ldots,\left(\mathbf{x}_{n_s}^s,y_{n_s}^s\right)\right\}$ , 其中 $\mathbf{x}_i^s\in\mathcal{X}_S$ 是源数据特征， $y_i^s\in\mathcal{Y}_S$ 是源数据标签，回归任务因此标签为连续变量。同时有另一个相似的回归任务，仅有少量的标签数据 $\mathcal{D}_T=\left\{\left(\mathbf{x}_1^t,y_1^t\right),\ldots,\left(\mathbf{x}_{n_t}^t,y_{n_t}^t\right)\right\}$ , 其中 $\mathbf{x}_i^t  \in \mathcal{X}_T$ 是输入， $y_i^t\in\mathcal{Y}_T$ 对应的输出。此处所关注的是两个回归任务的条件偏移场景，即假设边缘分布相同 ​，而条件分布不同，即$P\left(y_s\middle|\mathbf{x}_s\right)\neq P\left(y_t\middle|\mathbf{x}_t\right)$。</p>
<p>为了后面更加清晰描述，此处定义清楚两数据集的所需表示：</p>
<p>源数据    $\mathcal{D}_s$, 包含输入特征矩阵 ${\mathbf{X}}_s\in\mathbb{R}^{n_s\times d}$ 和输出标签向量 ${\mathbf{y}}_s\in\mathbb{R}^{n_s\times 1}$ :</p>
<script type="math/tex; mode=display">
\mathbf{X}_{s}=\left[\mathbf{x}_{1}^{s}, \mathbf{x}_{2}^{s}, \ldots, \mathbf{x}_{n_{s}}^{s}\right]^{\top}, \mathbf{y}_{s}=\left[y_{1}^{s}, y_{2}^{s}, \ldots, y_{n_{s}}^{s}\right]^{\top}</script><p>目标数据 $\mathcal{D}_t$, 包含输入特征矩阵 ${\mathbf{X}}_t\in\mathbb{R}^{n_t\times d}$ 和输出标签向量 ${\mathbf{y}}_t\in\mathbb{R}^{n_t\times 1}$ :</p>
<script type="math/tex; mode=display">
\mathbf{X}_{t}=\left[\mathbf{x}_{1}^{t}, \mathbf{x}_{2}^{t}, \ldots, \mathbf{x}_{n_{t}}^{t}\right]^{\top}, \mathbf{y}_{t}=\left[y_{1}^{t}, y_{2}^{t}, \ldots, y_{n_{t}}^{t}\right]^{\top}</script><h3 id="2-问题转化"><a href="#2-问题转化" class="headerlink" title="2. 问题转化"></a>2. 问题转化</h3><p>回归问题的条件分布差异表示如下图，一般来说，在不考虑输出不确定度的情况下，我们用条件分布的期望来表示回归函数的输出，即 $\mathbb{E}[y_s|x]$ 。</p>
<p><img src="/2019/12/18/GMMTL/Fig1 Illustration of conditional distribution shift.svg" style="zoom:70%;"></p>
<p>因此，条件分布的差异在回归问题上体现为条件期望的差异 $\mathbb{E}[y_s|\mathbf{x}]\neq\mathbb{E}[y_t|\mathbf{x}]$ ，在整个特征空间范围内，将条件分布差异定义为偏差项(discrepance)定义为 $h(\mathbf{x})$，由于期望取值为连续变量，因此残差项总可以表示为：</p>
<script type="math/tex; mode=display">
h(\mathbf{x})=\mathbb{E}[y_s|\mathbf{x}]-\mathbb{E}[y_t|\mathbf{x}]</script><p>因此迁移问题转换成求解偏差函数 $h(\mathbf{x})$的问题，若目标数据的数量 $\mathcal{D}_T$ 是足够多的，那么问题很简单，可以表示最小化如下损失函数：</p>
<script type="math/tex; mode=display">
J=\int_{\mathcal{X}_T} \{h(\mathbf{x})+\mathbb{E}[y_t|\mathbf{x}]-\mathbb{E}[y_s|\mathbf{x}]\}^{2} p(\mathbf{x}) \mathrm{d} \mathbf{x}</script><p>问题是，之所以需要迁移，是因为目标数据的数量是不充分的，对于直接求解 $\mathbb{E}[y_t|\mathbf{x}]$ 是不充分的也就是说对于直接求解 $\mathbb{E}[L]$是不充分的，因此我们需要利用其他假设信息来对问题进行转化，考虑到 $P(\mathbf{x}_s)=P(\mathbf{x}_t)$ ，因此我们用一组$K$维混合高斯分布来描述两个领域的特征空间分布：</p>
<script type="math/tex; mode=display">
p(\mathbf{x})=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)</script><p>即$P(\mathbf{x}_s)=P(\mathbf{x}_t)=p(\mathbf{x})$，其中$\sum_{k=1}^{K} \pi_{k}=1$ 为高斯混合模型的混合系数。此时，为了描述变量对与每个高斯高斯分布的归属情况， 我们引入变量 $\mathbf{z}\in\mathbb{R}^{K\times 1}$ ，向量 $\mathbf{z}$ 只有一个元素为1，其他元素都为0，也就是$\sum_{k} z_{k}=1$， 因此向量 $\mathbf{z}$ 共有 $K$ 种状态，对于样本 $\mathbf{x}$ 归属于第 $k$ 个高斯分布的情况，即 $z_k=1$，其概率可以表示为高斯混合模型的混合系数，即$p\left(z_{k}=1\right)=\pi_{k}$。由于向量中只有一个量为1，其他都为0，那么向量 $\mathbf{z}$ 的概率可以表示为 $p(\mathbf{z})=\prod_{k=1}^{K} \pi_{k}^{z_{k}}$。</p>
<p>在隐变量 $\mathbf{z}$ 的存在之下，观测样本的概率可以表示为：</p>
<script type="math/tex; mode=display">
p(\mathbf{x})=\int_{\mathbf{z}}p(\mathbf{x}, \mathbf{z})\mathrm{d}\mathbf{z}=\int_{\mathbf{z}} p(\mathbf{z}) p(\mathbf{x} | \mathbf{z})\mathrm{d}\mathbf{z}=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)</script><p><strong>请注意，重要的一步，由于变量 $\mathbf{x}$ 的概率由变量 $\mathbf{z}$ 隐式定义，那么我们认为变量 $\mathbf{x}$ 的偏差函数可以由变量 $\mathbf{z}$ 的偏差函数定义，因此定义隐变量的偏差函数 $w(\mathbf{\mathbf{z}})$，将 $\mathbf{x}$ 的偏差函数表示为</strong>：</p>
<script type="math/tex; mode=display">
h(\mathbf{x})=\int_{\mathbf{z}}w(\mathbf{z})p(\mathbf{z} | \mathbf{x})\mathrm{d}\mathbf{z}=\sum_{k=1}^{K} w(z_{k}=1)p(z_{k}=1 | \mathbf{x})</script><p>经过转化可见，求解$h(\mathbf{x})$的问题转化为更容易求解的 $r(\mathbf{\mathbf{z}})$，由于变量 $\mathbf{z}$ 共有$K$个状态，因此$w(z_{k}=1)$ 可以简化表示为 $w(k)$。此时损失函数(4)可以表示为：</p>
<script type="math/tex; mode=display">
J=\sum_{n=1}^{n_t}\sum_{k=1}^{K} \{w(k)p(z_{k}=1 | \mathbf{x}_n^t)+\mathbb{E}[y_t|\mathbf{x}_n^t]-\mathbb{E}[y_s|\mathbf{x}_n^t]\}^{2}</script><h3 id="3-求解隐变量偏差函数"><a href="#3-求解隐变量偏差函数" class="headerlink" title="3 求解隐变量偏差函数"></a>3 求解隐变量偏差函数</h3><p>关于偏差函数  $w(\mathbf{\mathbf{z}})$，以下给出三种解法。</p>
<h4 id="3-1-Method-A-最小平方误差求解"><a href="#3-1-Method-A-最小平方误差求解" class="headerlink" title="3.1 Method A: 最小平方误差求解"></a>3.1 Method A: 最小平方误差求解</h4><p>对于损失函数(8)，对于给定目标数据集 $\mathcal{D}_T$, $\mathbb{E}[y_t|\mathbf{x}_n^t]=y^t_n$ 为已知量。设基于源数据 $\mathcal{D}_S$训练回归模型$f_s(\mathbf{x})$，那么可得 $\mathbb{E}[y_s|\mathbf{x}_n^t]=f_s(\mathbf{x}_n^t)$ 。另一个未知量$p(\mathbf{z} | \mathbf{x})$可由贝叶斯公式得到：</p>
<script type="math/tex; mode=display">
p(\mathbf{z} | \mathbf{x})=\frac{p(\mathbf{x} | \mathbf{z})p( \mathbf{z})}{p(\mathbf{x})}={\frac{ \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{k}, \boldsymbol{\Sigma}_{k}\right) \prod_{k=1}^{K} \pi_{k}^{z_{k}}}{\sum_{j=1}^{K} \pi_{j} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu}_{j}, \mathbf{\Sigma}_{j}\right)}}</script><p>令$\gamma\left(z_{n k}\right)= p\left(z_{k}=1 | \mathbf{x}_n\right)$，那么：</p>
<script type="math/tex; mode=display">
\gamma\left(z_{n k}\right)=\frac{\pi_{k} \mathcal{N}\left(\mathbf{x}_{n} | \boldsymbol{\mu}_{k}, \boldsymbol{\Sigma}_{k}\right)}{\sum_{j=1}^{K} \pi_{j} \mathcal{N}\left(\mathbf{x}_{n} | \boldsymbol{\mu}_{j}, \mathbf{\Sigma}_{j}\right)}</script><p>令因此，损失函数可以表示为：</p>
<script type="math/tex; mode=display">
J=\sum_{n=1}^{n_t}\sum_{k=1}^{K} \{w(k)\gamma(z_{n k})+y^t_n-f_s(\mathbf{x}_n^t)\}^{2}+\lambda\mathbf{w}^{\top}\mathbf{w}</script><p>对损失函数求导，并令导数等于零得：</p>
<script type="math/tex; mode=display">
\mathbf{\Gamma}\mathbf{w}+\mathbf{y}_{t}-f_s(\mathbf{X}_{t})=0</script><p>因此可得最小二乘解：</p>
<script type="math/tex; mode=display">
\mathbf{w}=(\mathbf{\Gamma}^{\top}\mathbf{\Gamma}+\lambda\mathbf{I})^{-1}\mathbf{\Gamma}^{\top}(f_s(\mathbf{X}_{t})-\mathbf{y}_{t})</script><p>式子中矩阵 $\Gamma\in\mathbb{R}^{n_t\times K}$ 的每个元素为$\gamma(z_{n k})=p(z_k=1 | \mathbf{x}_t^n)$ , $\mathbf{w}\in\mathbb{R}^{K\times 1}$。</p>
<h4 id="3-2-Method-B-Method-What"><a href="#3-2-Method-B-Method-What" class="headerlink" title="3.2 Method B: Method What?"></a>3.2 Method B: Method What?</h4><p>第二种思路没想好对应的什么理论。逆向思维思考问题，首先我有：</p>
<script type="math/tex; mode=display">
h(\mathbf{x})=\int_{\mathbf{z}}w(\mathbf{z})p(\mathbf{z} | \mathbf{x})\mathrm{d}\mathbf{z}</script><p><strong>直观上的一组解法如下，不过我不知道为什么可以这么解：</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
w(\mathbf{z})=&\frac{\int_{n_t}h(\mathbf{x})p(\mathbf{x} | \mathbf{z})\mathrm{d}\mathbf{x}}{\int_{n_t}p(\mathbf{x} | \mathbf{z})\mathrm{d}\mathbf{x}}

\end{aligned}</script><p>$w(\mathbf{z})$ 对应的是$K$ 个规则的偏差值，因此每个规则对应的偏差值可以表示为：</p>
<script type="math/tex; mode=display">
w_k=\frac{\sum_{n=1}^{n_t}h(\mathbf{x}_n^t)p(\mathbf{x}|z_{k}=1 )}{\sum_{n=1}^{n_t}p(\mathbf{x}_n^t|z_{k}=1 )}
=\frac{\sum_{n=1}^{n_t}h(\mathbf{x}_n^t)\pi_{k} \mathcal{N}\left(\mathbf{x}_n^t | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)}{\sum_{n=1}^{n_t}\pi_{k} \mathcal{N}\left(\mathbf{x}_n^t | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)}</script><p>即为：</p>
<script type="math/tex; mode=display">
w_k=\frac{\sum_{n=1}^{n_t}(f_s(\mathbf{x}_n^t)-y^t_n)\pi_{k} \mathcal{N}\left(\mathbf{x}_n^t | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)}{\sum_{n=1}^{n_t}\pi_{k} \mathcal{N}\left(\mathbf{x}_n^t | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)}</script><h4 id="3-3-Method-C-条件分布核适配"><a href="#3-3-Method-C-条件分布核适配" class="headerlink" title="3.3  Method C: 条件分布核适配"></a>3.3  Method C: 条件分布核适配</h4><p>参照CMU的论文，可以以适配条件分布核均值为约束，优化参数  $\mathbf{w}$，具体如下：</p>
<p>我们目标定义为最佳偏置函数应满足条件嵌入算子匹配，即损失函数定义为</p>
<script type="math/tex; mode=display">
L=\left\|\hat{\mathcal{U}}\left[P_{\mathbf{y}_{s}^{new}| X_{s}} \right]-\hat{\mathcal{U}}\left[P_{\mathbf{y}_{t} | X_{t}}\right]\right\|_\mathscr{H}^{2}+\lambda\mathbf{w}^{\top}\mathbf{w}</script><p>其中：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{s}^{new}=\mathbf{y}_{s}-h(\mathbf{X}_s)=\mathbf{y}_{s}-\mathbf{\Gamma}_s\mathbf{w}</script><p>式子中矩阵 $\Gamma_s\in\mathbb{R}^{n_s\times K}$ 的每个元素为 $\gamma(z_{n k})=p(z_k=1 | \mathbf{x}_s^n)$ ， $\mathbf{w}\in\mathbb{R}^{K\times 1}$。</p>
<p>条件嵌入算子表示为：</p>
<script type="math/tex; mode=display">
\hat{\mathcal{U}}\left[P_{Y | X}\right]=\Psi(Y)\left(K_{X X}+\lambda I\right)^{-1} \Phi^{\top}(X)</script><p>因此最终损失函数表示为：</p>
<script type="math/tex; mode=display">
L=\left\|\psi\left(\mathbf{y}_{s}^{new}\right)\left(K_{\mathbf{X}_{s} \mathbf{X}_{s}}+\lambda I\right)^{-1} \phi^{\top}\left(\mathbf{X}_{s}\right)-\psi\left(\mathbf{y}_{t}\right)\left(K_{\mathbf{X}_{t} \mathbf{X}_{t}}+\lambda I\right)^{-1} \phi^{\top}\left(\mathbf{X}_{t}\right)\right\|_\mathscr{H}^{2}</script><p>可以用梯度下降法求解 $\mathbf{w}$ 。</p>
<h3 id="4-曲线实验"><a href="#4-曲线实验" class="headerlink" title="4. 曲线实验"></a>4. 曲线实验</h3><p>sin曲线上实际测试如下，其中Method C的参数实在难调：</p>
<p><img src="/2019/12/18/GMMTL/Fig2 GMMTL.svg" style="zoom:67%;"></p>

          
        
      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tangmeii.cn/2019/12/11/Mixture of Gaussians/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gengxiang">
      <meta itemprop="description" content="某航空人">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tangmeii_Sites">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/12/11/Mixture of Gaussians/" class="post-title-link" itemprop="http://tangmeii.cn/index.html">Chapter 9 Mixture of Gaussians and EM</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-12-11 19:08:46" itemprop="dateCreated datePublished" datetime="2019-12-11T19:08:46+08:00">2019-12-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2020-02-14 23:07:00" itemprop="dateModified" datetime="2020-02-14T23:07:00+08:00">2020-02-14</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/学习/" itemprop="url" rel="index"><span itemprop="name">学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>如果我们定义了一个观测变量和隐变量的联合分布，那么观测变量的分布就可以通过对隐变量边缘化得到，也就是把隐变量积分掉。因此，<strong>可以把难以求解的观测变量的边缘分布扩展至一种相对容易处理的方式，即扩展到由观测变量和隐变量构成的联合分布</strong>，潜变量的引入可以把复杂的分布拆解成简单的分布。<br></p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/12/11/Mixture of Gaussians/" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
         
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tangmeii.cn/2019/10/16/Pytorch语法/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gengxiang">
      <meta itemprop="description" content="某航空人">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tangmeii_Sites">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/10/16/Pytorch语法/" class="post-title-link" itemprop="http://tangmeii.cn/index.html">Pytorch语法</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-16 15:53:38" itemprop="dateCreated datePublished" datetime="2019-10-16T15:53:38+08:00">2019-10-16</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-17 20:59:25" itemprop="dateModified" datetime="2019-10-17T20:59:25+08:00">2019-10-17</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/学习/" itemprop="url" rel="index"><span itemprop="name">学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h2><p>矩阵点乘，即对应元素相乘</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">numpy   : A * B </span><br><span class="line">matlab  : A.*B</span><br><span class="line">pytorch : A.mul(B)</span><br></pre></td></tr></table></figure>
<p>矩阵运算相乘，即 $A\in{R^{n\times m}},$ $B\in{R^{m\times n}}$, $AB\in R^{n\times n}$</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">numpy   : <span class="type">np.dot</span>(A, B) </span><br><span class="line">matlab  : <span class="type">A</span>*B</span><br><span class="line">pytorch : <span class="type">A.mm</span>(B)</span><br></pre></td></tr></table></figure>
<h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>查到数组中大于3的元素及索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">numpy   : out = [i <span class="keyword">for</span> i, x <span class="keyword">in</span> enumerate(e) <span class="keyword">if</span> x &gt; <span class="number">3</span>]</span><br><span class="line">matlab  : out = find(e &gt; <span class="number">3</span>)</span><br><span class="line">pytorch : out = e[e.gt(<span class="number">3</span>)] <span class="comment"># gt大于 lt小于  eq等于</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tangmeii.cn/2019/09/29/Multisource-AT-GP-by-stacking/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gengxiang">
      <meta itemprop="description" content="某航空人">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tangmeii_Sites">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/29/Multisource-AT-GP-by-stacking/" class="post-title-link" itemprop="http://tangmeii.cn/index.html">Multisource AT-GP by stacking</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-09-29 17:41:57 / 修改时间：17:57:43" itemprop="dateCreated datePublished" datetime="2019-09-29T17:41:57+08:00">2019-09-29</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/学习/" itemprop="url" rel="index"><span itemprop="name">学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="Source-Target-Similarity-Modeling"><a href="#Source-Target-Similarity-Modeling" class="headerlink" title="Source-Target Similarity Modeling"></a>Source-Target Similarity Modeling</h2><p>2010 Cao 提出了单源数据的transfer covariance function,本文将其称作$TC_{\text{SS}}$，基于此的迁移学习方法就叫做$\text{GP} -<br>TC_{\text{SS}}$。本文针对的是多源问题，就是$TC_{\text{MS}}$，直观上，可以对每个源都按照$TC_{\text{SS}}$去构造，但是本文证明直接利用是不可行的。本文提出了Stacking的方法。</p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/09/29/Multisource-AT-GP-by-stacking/" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
         
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tangmeii.cn/2019/09/29/Adaptive-transfer-learning-AT-GP/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gengxiang">
      <meta itemprop="description" content="某航空人">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tangmeii_Sites">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/29/Adaptive-transfer-learning-AT-GP/" class="post-title-link" itemprop="http://tangmeii.cn/index.html">Adaptive transfer learning AT-GP</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-09-29 17:41:31 / 修改时间：18:15:53" itemprop="dateCreated datePublished" datetime="2019-09-29T17:41:31+08:00">2019-09-29</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/学习/" itemprop="url" rel="index"><span itemprop="name">学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h3 id="The-Adaptive-Transfer-Learning-Model-via-Gaussian-Process"><a href="#The-Adaptive-Transfer-Learning-Model-via-Gaussian-Process" class="headerlink" title="- The Adaptive Transfer Learning Model via Gaussian Process"></a>- The Adaptive Transfer Learning Model via Gaussian Process</h3><p>AAAI Adaptive transfer leanring 为了使得源和目标任务之间能迁移知识，我们首先要定义两者之间的联系。一种方式就是使源和目标的核函数共享一些相同的参数$\mathbf{\theta}$，<strong>核函数代表了平滑性</strong>，共享核函数参数意味着两任务回归函数的平滑性相似。<strong>另一些方法利用了数据输出之间的关联性【这个可以关注一下】</strong>。本方法是半参数化，构造了<strong>任务之间的相似性</strong>和<strong>样本之间的相关性</strong></p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/09/29/Adaptive-transfer-learning-AT-GP/" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
         
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Gengxiang">
            
              <p class="site-author-name" itemprop="name">Gengxiang</p>
              <p class="site-description motion-element" itemprop="description">某航空人</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives">
                
                    <span class="site-state-item-count">22</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">12</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://github.com/gengxiangc" title="GitHub &rarr; https://github.com/gengxiangc" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="mailto:cgx@nuaa.edu.com" title="E-Mail &rarr; mailto:cgx@nuaa.edu.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://weibo.com/Tangmei_can" title="Weibo &rarr; https://weibo.com/Tangmei_can" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i></a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">  <a href="http://www.beian.miit.gov.cn" rel="noopener" target="_blank">苏ICP备18055599号 </a>&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Gengxiang</span>

  

  
</div>











        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv" title="总访客量">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="site-pv" title="总访问量">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

   
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
   
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  
    
      
  
  <script type="text/javascript" color="0,0,255" opacity="0.5" zindex="-1" count="99" src="/lib/canvas-nest/canvas-nest.min.js"></script>













  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.6.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.6.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.6.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.6.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.6.0"></script>



  



  










  





  

  

  

  

  
  

  
  
    
      
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
    overflow: auto hidden;
}
</style>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>


    
  


  
  

  

  

  

  

  

  

</body>
</html>
